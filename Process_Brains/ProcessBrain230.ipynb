{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "from scipy.ndimage import distance_transform_edt as dist\n",
    "import IPython.display \n",
    "import importlib\n",
    "import skimage.io as imgio\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from topoloss4neurons.networks import UNet\n",
    "import networktraining as nt\n",
    "# from topoloss4neurons import load_dataset\n",
    "%matplotlib inline\n",
    "def imshow(img):\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "    \n",
    "def showCube(vol):\n",
    "    v1=np.max(vol,axis=0)\n",
    "    v2=np.max(vol,axis=1)\n",
    "    v3=np.max(vol,axis=2)\n",
    "    imshow(v1*255)\n",
    "    imshow(v2*255)\n",
    "    imshow(v3*255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volInds(swcCoords,scale,volDims,offset,downsampling):\n",
    "    \"\"\"\n",
    "    For scaling and shifting coordinates\n",
    "    \"\"\"\n",
    "    x=int((swcCoords[volDims[0]]*scale[0]+offset[0])*downsampling[0])\n",
    "    y=int((swcCoords[volDims[1]]*scale[1]+offset[1])*downsampling[1])\n",
    "    z=int((swcCoords[volDims[2]]*scale[2]+offset[2])*downsampling[2])\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceLine(lbl,begPoint,endPoint):\n",
    "    \"\"\"\n",
    "    Renders a line represented by two nodes\n",
    "    \"\"\"\n",
    "    d=endPoint-begPoint\n",
    "    s=begPoint\n",
    "    mi=np.argmax(np.fabs(d))\n",
    "    coef=d/d[mi]\n",
    "    sz=np.array(lbl.shape)\n",
    "    numsteps=int(abs(d[mi]))+1\n",
    "    step=int(d[mi]/abs(d[mi]))\n",
    "    for t in range(0,numsteps):\n",
    "        pos=np.array(s+coef*t*step)\n",
    "        if np.all(pos<sz) and np.all(pos>=0):\n",
    "            #print(pos)\n",
    "            lbl[tuple(pos.astype(np.int))]=1\n",
    "#         else:\n",
    "#             print(\"reqested point\",pos,\"but the volume size is\",sz)\n",
    "    return lbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSWC(brain_i):\n",
    "    \"\"\"\n",
    "    Returns the full annotation information for the given brain index\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        swcfname = \"/cvlabdata2/home/oner/CarlsData/AL066-AL_stamp_2019_07_23_10_34.ano.eswc\"\n",
    "    elif brain_i == 8:\n",
    "        swcfname = \"/cvlabdata2/home/oner/CarlsData/AL080_stamp_2020_01_22_13_26.ano.eswc\"\n",
    "    elif brain_i == 9:\n",
    "        swcfname = \"/cvlabdata2/home/oner/CarlsData/AL092_stamp_2020_01_09_11_10.ano.eswc_sorted.eswc\"\n",
    "    elif brain_i == 175:\n",
    "        swcfname = \"/cvlabdata2/home/oner/CarlsData/annotations/AL175_stamp_2021_02_10_13_52.ano.eswc\"\n",
    "    elif brain_i == 223:\n",
    "        swcfname = None\n",
    "        return {0:[6833,7549,488],1:[3091,7665,410],2:[7088,7804,554],3:[3346,7920,665]}\n",
    "    elif brain_i == 230:\n",
    "        swcfname = None\n",
    "        return {0:[3935,8628,288],1:[4109,8883,543],2:[3713,8397,389],3:[3968,8653,644]}\n",
    "    else:\n",
    "        return\n",
    "    nodes=dict()\n",
    "    for a in open(swcfname):\n",
    "        if (re.match('\\s*\\#',a)!=None):\n",
    "#             print(\"commment line\", a)\n",
    "            continue\n",
    "        b=a.split()\n",
    "        c=map(lambda x: float(x), b)\n",
    "        d=list(c)\n",
    "        nodes[int(d[0])]=d\n",
    "    return nodes\n",
    "\n",
    "def getCoords(brain_i):\n",
    "    \"\"\"\n",
    "    Returns the location of nodes in the annotations\n",
    "    \"\"\"\n",
    "    nodes = readSWC(brain_i)\n",
    "    coords = []\n",
    "    for k in nodes :\n",
    "        n=nodes[k]\n",
    "        if brain_i == 6:\n",
    "            x,y,z= volInds(n,[1,1,1],[2,3,4], [0,0,0], [1,1,1])\n",
    "        elif brain_i == 8:\n",
    "            x,y,z= volInds(n,[1,1,1],[2,3,4], [0,0,0], [1,1,1])\n",
    "        elif brain_i == 9:\n",
    "            x,y,z= volInds(n,[1,1,1],[2,3,4], [0,0,0], [1,1,1])\n",
    "        elif brain_i == 175:\n",
    "            x,y,z= volInds(n,[1,1,1],[2,3,4], [0,0,0], [1,1,1])\n",
    "        elif brain_i == 223:\n",
    "            x,y,z= volInds(n,[1,1,1],[0,1,2], [0,0,0], [1,1,1])\n",
    "        elif brain_i == 230:\n",
    "            x,y,z= volInds(n,[1,1,1],[0,1,2], [0,0,0], [1,1,1])\n",
    "        coords.append([x,y,z])\n",
    "    return coords\n",
    "\n",
    "def renderSWC2volume(swcfname, volumeDims, volCL, scale, offset, downsampling):\n",
    "    '''\n",
    "      swcfname      name of the swc file\n",
    "      volumeDims    one-dimensional array;\n",
    "                    volumeDims[1] is index of volCL dimension corresponding to X\n",
    "                    volumeDims[2] is index of volCL dimension corresp to Y\n",
    "                    volumeDims[3] is index of volCL dimension corresp to Z\n",
    "                    X,Y,Z are as interpreted in the CWS format\n",
    "      volCL         np array into which we will render ground truth centerlines\n",
    "    '''\n",
    "    distthresh=40\n",
    "    nodes=dict()\n",
    "    for a in open(swcfname):\n",
    "        if (re.match('\\s*\\#',a)!=None):\n",
    "#             print(\"commment line\", a)\n",
    "            continue\n",
    "        b=a.split()\n",
    "        c=map(lambda x: float(x), b)\n",
    "        d=list(c)\n",
    "        nodes[int(d[0])]=d\n",
    "        #print(d)\n",
    "    # start here\n",
    "    for k in nodes :\n",
    "        n=nodes[k]\n",
    "        x,y,z= volInds(n,scale,volumeDims, offset, downsampling)\n",
    "        parent=nodes.get(int(n[6]),None)\n",
    "        #print(n)\n",
    "        if parent!=None :\n",
    "            #print(n,parent)\n",
    "            xp,yp,zp=volInds(parent,scale,volumeDims, offset, downsampling)\n",
    "            #print(x,y,z,volCL.shape)\n",
    "            #print(xp,yp,zp,volCL.shape)\n",
    "            if (x!=xp or y!=yp or z!=zp) and ((abs(x-xp)+abs(y-yp)+abs(z-zp))<distthresh):\n",
    "                #print(\"line: ({},{},{})-({},{},{})\".format(xp,yp,zp,x,y,z))\n",
    "                traceLine(volCL,np.array([xp,yp,zp]),np.array([x,y,z]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCubeCoords(brain_i):\n",
    "    \"\"\"\n",
    "    Returns xyz borders of the cubes according to terafiles\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/home/oner/samba/TeraConvertion/AL230/RES(14504x17408x2468)/\"\n",
    "    else:\n",
    "        return\n",
    "    yind = sorted([int(x)//10 for x in os.listdir(direc) if x.startswith(\"0\") or x.startswith(\"1\")] )\n",
    "    xind = sorted([int(x.split(\"_\")[-1])//10 for x in os.listdir(os.path.join(direc,\"000000\")) if x.startswith(\"0\") or x.startswith(\"1\")] )\n",
    "    zind = sorted([int(x.split(\"_\")[-1][:-4])//10 for x in os.listdir(os.path.join(direc,\"000000\", \"000000_000000\")) if x.startswith(\"0\") or x.startswith(\"1\")] )\n",
    "    \n",
    "    return xind, yind, zind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile\n",
    "def getCube(brain_i, cube):\n",
    "    \"\"\"\n",
    "    Returns the image of the desired cube in the desired brain\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/home/oner/samba/Ter/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/home/oner/samba/TeraConvertion/AL230/RES(14504x17408x2468)/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}.tif\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    volume = tifffile.imread(os.path.join(direc,l1,l2,l3))\n",
    "    return volume.transpose((1,2,0))\n",
    "\n",
    "def getCubename(brain_i, cube):\n",
    "    \"\"\"\n",
    "    Returns the directory for the desired cube\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/home/oner/samba/TeraConvertion/AL230/RES(14504x17408x2468)/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}.tif\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    \n",
    "    return os.path.join(\"/datasets/\" + direc.split(\"/\")[-2],l1,l2,l3)\n",
    "\n",
    "def getLabel(brain_i,cube):\n",
    "    \"\"\"\n",
    "    Returns the label of the desired cube in the desired brain\n",
    "    \"\"\"\n",
    "    xs, ys, zs = getCubeCoords(brain_i)\n",
    "    xi, xf = xs[cube[0]:cube[0]+2]\n",
    "    yi, yf = ys[cube[1]:cube[1]+2]\n",
    "    zi, zf = zs[cube[2]:cube[2]+2]\n",
    "    m=[1,1,1]\n",
    "    o=[-int(yi),-int(xi),-int(zi)]\n",
    "    scale_factor=[1,1,1]\n",
    "\n",
    "    downsampling=torch.tensor(scale_factor,dtype=torch.double)\n",
    "    offset=torch.tensor(o,dtype=torch.double)\n",
    "    scale=torch.tensor(m,dtype=torch.double)\n",
    "    volDims=torch.tensor([3,2,4],dtype=torch.long)\n",
    "    vols = np.zeros((yf-yi,xf-xi,zf-zi), dtype=np.uint8)\n",
    "    if brain_i == 6:\n",
    "        renderSWC2volume(swcname1, volDims, vols, scale, offset, downsampling)\n",
    "    elif brain_i == 8:\n",
    "        renderSWC2volume(swcname2, volDims, vols, scale, offset, downsampling)\n",
    "    elif brain_i == 9:\n",
    "        renderSWC2volume(swcname3, volDims, vols, scale, offset, downsampling)\n",
    "    elif brain_i == 175:\n",
    "        renderSWC2volume(swcname4, volDims, vols, scale, offset, downsampling)\n",
    "    else:\n",
    "        return\n",
    "    return vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCubes(brain_i):\n",
    "    \"\"\"\n",
    "    If the annotation is provided, returns the indices of cubes which contains annotated pixels\n",
    "    \"\"\"\n",
    "    xs, ys, zs = getCubeCoords(brain_i)\n",
    "    coords = getCoords(brain_i)\n",
    "    cubes = []\n",
    "    if len(coords) == 0:\n",
    "        cubes = np.array(np.meshgrid(np.arange(len(xs)),np.arange(len(ys)),np.arange(len(zs)))).T.reshape((-1,3))\n",
    "    for c in coords:\n",
    "        xi = np.where(c[0] > np.array(xs))[0][-1]\n",
    "        yi = np.where(c[1] > np.array(ys))[0][-1]\n",
    "        zi = np.where(c[2] > np.array(zs))[0][-1]\n",
    "        if [xi,yi,zi] not in cubes:\n",
    "            cubes.append([xi,yi,zi])\n",
    "    return cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPred(brain_i, cube):\n",
    "    \"\"\"\n",
    "    Returns the prediction of the desired cube in the desired brain\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)/\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL230/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}.npy\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    pred = np.load(os.path.join(direc,l1,l2,l3)).transpose(2,0,1)\n",
    "    return pred\n",
    "\n",
    "def loadPredf(brain_i, cube):\n",
    "    \"\"\"\n",
    "    Returns the prediction_f of the desired cub in the desired brain\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)/\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL230/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}_f.npy\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    pred = np.load(os.path.join(direc,l1,l2,l3)).transpose(2,0,1)\n",
    "    return pred\n",
    "\n",
    "def savePred(brain_i, cube, pred):\n",
    "    \"\"\"\n",
    "    Saves the prediction for the desired cub in the desired brain\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)/\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL230/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}.npy\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    nt.utils.mkdir(os.path.join(direc,l1,l2))\n",
    "    np.save(os.path.join(direc,l1,l2,l3), pred.transpose(1,2,0))\n",
    "    \n",
    "def savePredf(brain_i, cube, pred):\n",
    "    \"\"\"\n",
    "    Saves the prediction_f for the desired cub in the desired brain\n",
    "    \"\"\"\n",
    "    if brain_i == 6:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/6RES(11711x16382x2000)/\"\n",
    "    elif brain_i == 8:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/8RES(11692x19566x1600)/\"\n",
    "    elif brain_i == 9:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/9RES(11692x16123x1700)/\"\n",
    "    elif brain_i == 175:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/AL175/RES(15186x17117x1919)/\"\n",
    "    elif brain_i == 223:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL223/\"\n",
    "    elif brain_i == 230:\n",
    "        direc = \"/cvlabdata2/home/oner/CarlsData/Data/AL230/\"\n",
    "    else:\n",
    "        return\n",
    "    xs,ys,zs = getCubeCoords(brain_i)\n",
    "    x,y,z = cube\n",
    "    l1 = \"{:06d}\".format(ys[y]*10)\n",
    "    l2 = \"{:06d}_{:06d}\".format(ys[y]*10,xs[x]*10)\n",
    "    l3 = \"{:06d}_{:06d}_{:06d}_f.npy\".format(ys[y]*10,xs[x]*10,zs[z]*10)\n",
    "    nt.utils.mkdir(os.path.join(direc,l1,l2))\n",
    "    np.save(os.path.join(direc,l1,l2,l3), pred.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swcname=\"/cvlabdata2/home/kozinski/MBFneuron/DeFelipe_Auto_DK_Edited_Complete.SWC\"\n",
    "swcname1 = \"/cvlabdata2/home/oner/CarlsData/AL066-AL_stamp_2019_07_23_10_34.ano.eswc\"\n",
    "swcname2 = \"/cvlabdata2/home/oner/CarlsData/AL080_stamp_2020_01_22_13_26.ano.eswc\"\n",
    "swcname3 = \"/cvlabdata2/home/oner/CarlsData/AL092_stamp_2020_01_09_11_10.ano.eswc_sorted.eswc\"\n",
    "swcname4 = \"/cvlabdata2/home/oner/CarlsData/AL175_stamp_2021_02_10_13_52.ano.eswc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = readSWC(175)\n",
    "coords = getCoords(175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,zs = getCubeCoords(175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = findCubes(175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(cube_i, which_n=[], is_all=False):\n",
    "    \"\"\"\n",
    "    Returns the indices of neighbour cubes of the desired cube\n",
    "    which_n : If you want to specify which neighbours you want to get\n",
    "    \"\"\"\n",
    "    neighs = []\n",
    "    if is_all:\n",
    "        for i in range(6):\n",
    "            n = [0,0,0]\n",
    "            if i < 3:\n",
    "                n[i] = 1\n",
    "            else:\n",
    "                n[i%3] = -1\n",
    "            neighs.append(list(np.array(cube_i) + np.array(n)))\n",
    "    else:\n",
    "        for n in which_n:\n",
    "            neighs.append(list(np.array(cube_i) + np.array(n)))\n",
    "        return neighs\n",
    "    \n",
    "    return neighs\n",
    "\n",
    "def checkBorders(pred, th=3, border=5):\n",
    "    \"\"\"\n",
    "    For the given prediction check which borders of the cube contains foreground voxels\n",
    "    th : Threshold to binarize the prediction\n",
    "    border : width of border region you want to check for foreground voxels\n",
    "    \"\"\"\n",
    "    borders = []\n",
    "    pred_bin = pred < th\n",
    "    if np.sum(pred_bin[:border,:,:]) > 0:\n",
    "        borders.append([0,-1,0])\n",
    "    if np.sum(pred_bin[:,:border,:]) > 0:\n",
    "        borders.append([-1,0,0])\n",
    "    if np.sum(pred_bin[:,:,:border]) > 0:\n",
    "        borders.append([0,0,-1])\n",
    "    if np.sum(pred_bin[-border:,:,:]) > 0:\n",
    "        borders.append([0,1,0])\n",
    "    if np.sum(pred_bin[:,-border:,:]) > 0:\n",
    "        borders.append([1,0,0])\n",
    "    if np.sum(pred_bin[:,:,-border:]) > 0:\n",
    "        borders.append([0,0,1])\n",
    "    return borders\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    pred = network(chunk)\n",
    "    return pred\n",
    "\n",
    "def segmentCube(im, network):\n",
    "    \"\"\"\n",
    "    Segments the given image with the given network\n",
    "    \"\"\"\n",
    "    with nt.torch_no_grad:\n",
    "        image_i = np.float32(im[None,None])\n",
    "        image_i  = nt.to_torch(image_i, volatile=True).contiguous().to(\"cuda\")\n",
    "        out_shape = (image_i.shape[0],1,*image_i.shape[2:])\n",
    "        pred_i = nt.to_torch(np.empty(out_shape, np.float32), volatile=True).cuda()\n",
    "        pred_i = nt.process_in_chuncks(image_i, pred_i, process_chunk,\n",
    "                                       [96,96,96], [12,12,12])\n",
    "        pred_np = pred_i.detach().cpu().numpy()[0,0]\n",
    "        return pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = UNet(in_channels=1,\n",
    "                   m_channels=32,\n",
    "                   out_channels=1,\n",
    "                   n_convs=2,\n",
    "                   n_levels=5,\n",
    "                   dropout=0.1,\n",
    "                   batch_norm=True,\n",
    "                   upsampling=\"deconv\",\n",
    "                   pooling=\"max\",\n",
    "                   three_dimensional=True).to(\"cuda\")\n",
    "\n",
    "network.load_state_dict(torch.load(\"/cvlabdata2/home/oner/CarlsData/new_logs/log_base_5lvl_2convs/network_bestqual.pickle\"))\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "ttt = time.time()\n",
    "save = True\n",
    "# Keeps track of the already segmented cubes so that we don't segment them again\n",
    "processed_cubes = []\n",
    "# Cubes in queue for segmenting\n",
    "pending_cubes = []\n",
    "\n",
    "## Select random starting cubes\n",
    "starting_cubes = np.random.choice(len(cubes),4,replace=False)\n",
    "starting_cubes = [cubes[i] for i in starting_cubes]\n",
    "# Add all given statring cubes to the queue\n",
    "for sc in starting_cubes:\n",
    "    pending_cubes.append(sc)\n",
    "ii = 0\n",
    "# Get the coordinates of the cube (jsut for printing)\n",
    "xs,ys,zs = getCubeCoords(175)\n",
    "\n",
    "while len(pending_cubes) > 0: # checks if there are any cubes in queue\n",
    "    current_cube = pending_cubes.pop(0) # get the first cube in queue\n",
    "    if current_cube in processed_cubes: # check if you already processed this cube\n",
    "        print(current_cube, \" already processed\")\n",
    "        continue\n",
    "    print(\"Processing \", current_cube)\n",
    "    print(xs[current_cube[0]],ys[current_cube[1]],zs[current_cube[2]])\n",
    "    \n",
    "    im = getCube(175, current_cube)/65535 # get the image of the cube and normalize the uint16 images\n",
    "    pred = segmentCube(im, network) # get the prediction\n",
    "\n",
    "    if save:\n",
    "        savePred(175, current_cube, pred) # save them if you want\n",
    "    which_n = checkBorders(pred, th=8, border=8) # check for border voxels and find the neighbours which probably contains neuron\n",
    "    \n",
    "    print(\"Neighbours \", getNeighbours(current_cube, which_n))\n",
    "    processed_cubes.append(current_cube)\n",
    "    pending_cubes += getNeighbours(current_cube, which_n) # add the neighbour according to border voxels\n",
    "    \n",
    "    if ii % 20:\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(im.max(2))\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(pred.min(2))\n",
    "        plt.show()\n",
    "        \n",
    "print(time.time()-ttt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Visualizing the big predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "\n",
    "# im2 = skimage.measure.block_reduce(im, (4,4,4), np.max)\n",
    "# pred2 = skimage.measure.block_reduce(pred, (4,4,4), np.min, cval=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the cubes and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_cubes = []\n",
    "for i in range(np.min(cubes,axis=0)[0], np.max(cubes,axis=0)[0]+1):\n",
    "    for j in range(np.min(cubes,axis=0)[1], np.max(cubes,axis=0)[1]+1):\n",
    "        for k in range(np.min(cubes,axis=0)[2], np.max(cubes,axis=0)[2]+1):\n",
    "            neuron_cubes.append([i,j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(cubes).max(0) - np.array(cubes).min(0) +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.array(cubes).max(0) - np.array(cubes).min(0) +1\n",
    "maxs = np.array(cubes).max(0)\n",
    "mins = np.array(cubes).min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Downscale the cubes by 4 and concat them in an array to visualize it\n",
    "## We are loading all the cubes in a big rectangle prism which contains the whole neuron\n",
    "ims = np.zeros((dims[2]*75,dims[0]*75,dims[1]*75))\n",
    "preds = 15*np.ones((dims[2]*75,dims[0]*75,dims[1]*75))\n",
    "imss = []\n",
    "predss = []\n",
    "x = 0\n",
    "y = 0\n",
    "z = 0\n",
    "ind = 0\n",
    "for i in range(mins[0],maxs[0]+1):\n",
    "    for j in range(mins[1],maxs[1]+1):\n",
    "        for k in range(mins[2],maxs[2]+1):\n",
    "            print(i,j,k)\n",
    "            im = np.float32(getCube(175, [i,j,k])/65535)\n",
    "            im2 = skimage.measure.block_reduce(im, (4,4,4), np.max)\n",
    "            try: # if it is segmented load the prediction\n",
    "                pred_np = loadPred(175, [i,j,k])\n",
    "                pred_np = skimage.measure.block_reduce(pred_np, (4,4,4), np.min, cval=15)\n",
    "                print(\"Loaded\")\n",
    "            except: # if it is an empty cube just put all 15 (because the highest value in distance map is 15)\n",
    "                pred_np = 15*np.ones(im2.shape)\n",
    "\n",
    "            imss.append(im2)\n",
    "            predss.append(pred_np)\n",
    "            shp = im2.shape\n",
    "            ims[z:z+shp[2],x:x+shp[1],y:y+shp[0]] = im2.transpose(2,1,0)\n",
    "            preds[z:z+shp[2],x:x+shp[1],y:y+shp[0]] = pred_np.transpose(2,1,0)\n",
    "            z += shp[2]\n",
    "        y += shp[0]\n",
    "        z = 0\n",
    "    x += shp[1]\n",
    "    y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ims2 = np.load(\"im175.npy\")\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(ims.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# preds2 = np.load(\"pred175.npy\")\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(preds2.min(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./im175.npy\", ims)\n",
    "np.save(\"./pred175.npy\", preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
