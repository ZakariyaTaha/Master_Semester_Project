{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the script i used to generate ground truths in form of graphs\n",
    "# from binary masks\n",
    "# i shall not try to clean it up since, these has been meant to be run just once\n",
    "# and since the dataset is pretty unique and will not be released publically\n",
    "# and the results seem ok for as much as they were verified (also in this script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import IPython.display \n",
    "import importlib\n",
    "import skimage.io as imgio\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from graph_routines import graph_from_3D_mask, detectAndRemoveClusters, cycleBasis, reduceCycleBasis, minCycleBasis, verifyEdges\n",
    "import scipy.sparse.csgraph as g\n",
    "from skimage.morphology import skeletonize_3d\n",
    "import pickle\n",
    "\n",
    "def imshow(img):\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "    \n",
    "def showCube(vol):\n",
    "    v1=np.max(vol,axis=0)\n",
    "    v2=np.max(vol,axis=1)\n",
    "    v3=np.max(vol,axis=2)\n",
    "    imshow(v1*255)\n",
    "    imshow(v2*255)\n",
    "    imshow(v3*255)\n",
    "def show2Cubes(vol1,vol2):\n",
    "    v11=np.max(vol1,axis=0)\n",
    "    v12=np.max(vol1,axis=1)\n",
    "    v13=np.max(vol1,axis=2)\n",
    "    v21=np.max(vol2,axis=0)\n",
    "    v22=np.max(vol2,axis=1)\n",
    "    v23=np.max(vol2,axis=2)\n",
    "    imshow(np.concatenate([v11,v21],1)*255)\n",
    "    imshow(np.concatenate([v12,v22],1)*255)\n",
    "    imshow(np.concatenate([v13,v23],1)*255)\n",
    "    \n",
    "def show3Cubes(vol1,vol2,vol3):\n",
    "    v11=np.max(vol1,axis=0)\n",
    "    v12=np.max(vol1,axis=1)\n",
    "    v13=np.max(vol1,axis=2)\n",
    "    v21=np.max(vol2,axis=0)\n",
    "    v22=np.max(vol2,axis=1)\n",
    "    v23=np.max(vol2,axis=2)\n",
    "    v31=np.max(vol3,axis=0)\n",
    "    v32=np.max(vol3,axis=1)\n",
    "    v33=np.max(vol3,axis=2)\n",
    "    imshow(np.concatenate([v11,v21,v31],1)*255)\n",
    "    imshow(np.concatenate([v12,v22,v32],1)*255)\n",
    "    imshow(np.concatenate([v13,v23,v33],1)*255)\n",
    "    \n",
    "def show4Cubes(vol1,vol2,vol3,vol4):\n",
    "    v11=np.max(vol1,axis=0)\n",
    "    v12=np.max(vol1,axis=1)\n",
    "    v13=np.max(vol1,axis=2)\n",
    "    v21=np.max(vol2,axis=0)\n",
    "    v22=np.max(vol2,axis=1)\n",
    "    v23=np.max(vol2,axis=2)\n",
    "    v31=np.max(vol3,axis=0)\n",
    "    v32=np.max(vol3,axis=1)\n",
    "    v33=np.max(vol3,axis=2)\n",
    "    v41=np.max(vol4,axis=0)\n",
    "    v42=np.max(vol4,axis=1)\n",
    "    v43=np.max(vol4,axis=2)\n",
    "    imshow(np.concatenate([v11,v21,v31,v41],1)*255)\n",
    "    imshow(np.concatenate([v12,v22,v32,v42],1)*255)\n",
    "    imshow(np.concatenate([v13,v23,v33,v43],1)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_routines import detectAndRemoveClusters, cycleBasis, reduceCycleBasis, minCycleBasis, verifyEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir=\"/cvlabdata2/home/kozinski/experimentsTorch/bbp_neurons/data_npy/img/train\"\n",
    "lbldir=\"/cvlabdata2/home/kozinski/experimentsTorch/bbp_neurons/newannot_npy/train\"\n",
    "testimgdir=\"/cvlabdata2/home/kozinski/experimentsTorch/bbp_neurons/data_npy/img/test\"\n",
    "testlbldir=\"/cvlabdata2/home/kozinski/experimentsTorch/bbp_neurons/newannot_npy/test\"\n",
    "exec(open(\"testFiles.txt\").read())\n",
    "exec(open(\"trainFiles.txt\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"/cvlabdata2/home/kozinski/experimentsTorch/bbp_neurons/data_npy/\"\n",
    "graphdir=os.path.join(datadir,\"newlbl_graph\")\n",
    "#os.mkdir(graphdir)\n",
    "traingraphdir=os.path.join(graphdir,\"train\")\n",
    "#os.mkdir(traingraphdir)\n",
    "testgraphdir=os.path.join(graphdir,\"test\")\n",
    "#os.mkdir(testgraphdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeCycle(edges,cycle):\n",
    "    nodes_cycle=np.nonzero(cycle.reshape(edges.shape))[0]\n",
    "    for k in nodes_cycle:\n",
    "        if edges[k].sum()<3: # not connected to the outside of the cycle\n",
    "            return k,True\n",
    "    return 0,False\n",
    "\n",
    "def removeCycles(edges,cycles):\n",
    "    nodes= np.array(range(edges.shape[0]))\n",
    "    nodes_to_be_removed=[]\n",
    "    succ = True\n",
    "    for c in cycles:\n",
    "        print(\"attempting to remove cycle length\",c.sum())\n",
    "        n,res=removeCycle(edges,c)\n",
    "        if res:\n",
    "            print(\"succeeded\")\n",
    "        else:\n",
    "            print(\"failed\")\n",
    "        succ=succ and res\n",
    "        if res:\n",
    "            nodes_to_be_removed.append(n)\n",
    "    edges=np.delete(edges,nodes_to_be_removed,axis=0)\n",
    "    edges=np.delete(edges,nodes_to_be_removed,axis=1)\n",
    "    nodes=np.delete(nodes,nodes_to_be_removed,axis=0)\n",
    "    return edges,nodes,succ\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for single dangling nodes\n",
    "def checkDangling(edges):\n",
    "    dangling=[]\n",
    "    singlyConnected=np.nonzero(edges.sum(1)==1)[0]\n",
    "    for k in singlyConnected:\n",
    "        nb=np.argmax(edges[k]).item()\n",
    "        if edges[nb].sum()>2:\n",
    "            #print(\"dangling node\")\n",
    "            dangling.append(k)\n",
    "    return np.array(dangling)\n",
    "\n",
    "def removeDangling(edges,nodes):\n",
    "    k=0\n",
    "    while k<edges.shape[0]:\n",
    "        if edges[k].sum()==1:\n",
    "            # k is singly connected\n",
    "            nb=np.argmax(edges[k]).item()\n",
    "            if edges[nb].sum()>2:\n",
    "                # the only neighbor of k is multiply connected\n",
    "                # so k is a dangling node\n",
    "                edges=np.delete(edges,(k),0)\n",
    "                edges=np.delete(edges,(k),1)\n",
    "                nodes=np.delete(nodes,(k),0)\n",
    "                continue\n",
    "        k=k+1\n",
    "    return edges,nodes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare graphs for training ground truths\n",
    "graphs=[]\n",
    "for f in trainFiles:\n",
    "  print(f)\n",
    "  img=np.load(os.path.join(imgdir,f[1])).astype(np.float32)\n",
    "  lbl=np.load(os.path.join(lbldir,f[1])).astype(np.float32)\n",
    "  #img=np.copy(img[:,0:100,0:100,0:100])\n",
    "  #lbl=np.copy(lbl[0:100,0:100,0:100])\n",
    "  #lbl[lbl<2]=0\n",
    "  #lbl=lbl/2\n",
    "  lbl_skeletonized=skeletonize_3d(lbl)\n",
    "  #showCube(lbl)\n",
    "  inds,edges,d2=graph_from_3D_mask(lbl)\n",
    "  #imshow(edges.astype(np.uint8)*255)\n",
    "  edges_nc,nodes_nc=detectAndRemoveClusters(edges)\n",
    "  inds_nc=inds[nodes_nc]\n",
    "  #imshow(edges_nc.astype(np.uint8)*255)\n",
    "  lbl_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_nc[inds_nc[k][0],inds_nc[k][1],inds_nc[k][2]]=1\n",
    "  show2Cubes(lbl_nc,lbl)\n",
    "  cycles_nc=minCycleBasis(edges_nc)\n",
    "  if len(cycles_nc)>0:\n",
    "    print(\"number cycles in the processed graph \",len(cycles_nc))\n",
    "    edges_rc,nodes_rc,res=removeCycles(edges_nc,cycles_nc)\n",
    "    inds_nc=inds_nc[nodes_rc]\n",
    "    edges_nc=edges_rc\n",
    "    if not res:\n",
    "        print(\"failed to remove a cycle\")\n",
    "        break\n",
    "  if not verifyEdges(edges_nc,inds_nc):\n",
    "    print(\"connection between non-neighboring voxels\")\n",
    "    break\n",
    "  num_cc_nc, component_labels_nc=g.connected_components(edges_nc)\n",
    "  lbl_color_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_color_nc[inds_nc[k][0],inds_nc[k][1],inds_nc[k][2]]=component_labels_nc[k]+1\n",
    "  lbl_color_nc=lbl_color_nc/float(num_cc_nc+1)\n",
    "  #showCube(lbl_color_nc)\n",
    "  #print( num_cc_nc )\n",
    "  num_cc, component_labels=g.connected_components(edges)\n",
    "  lbl_color=np.zeros_like(lbl)\n",
    "  for k in range(edges.shape[0]):\n",
    "    lbl_color[inds[k][0],inds[k][1],inds[k][2]]=component_labels[k]+1\n",
    "  lbl_color=lbl_color/float(num_cc+1)\n",
    "  show2Cubes(lbl_color,lbl_color_nc)\n",
    "  #print( num_cc )\n",
    "  if num_cc != num_cc_nc:\n",
    "    print(\"different number of connected components\")\n",
    "    break\n",
    "  assert(edges_nc.shape[0]==inds_nc.shape[0])\n",
    "  graphs.append([f,edges_nc,inds_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can check the graphs some more...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training ground truth graphs\n",
    "for gr in graphs:\n",
    "    ff=open(os.path.join(traingraphdir,gr[0][0]),\"bw\")\n",
    "    gt={'edges':gr[1],'node_coordinates':gr[2]}\n",
    "    pickle.dump(gt,ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare graphs for test ground truths\n",
    "graphs=[]\n",
    "for f in testFiles:\n",
    "  print(f)\n",
    "  img=np.load(os.path.join(testimgdir,f[1])).astype(np.float32)\n",
    "  lbl=np.load(os.path.join(testlbldir,f[1])).astype(np.float32)\n",
    "  #img=np.copy(img[:,0:100,0:100,0:100])\n",
    "  #lbl=np.copy(lbl[0:100,0:100,0:100])\n",
    "  #lbl[lbl<2]=0\n",
    "  #lbl=lbl/2\n",
    "  lbl_skeletonized=skeletonize_3d(lbl)\n",
    "  #showCube(lbl)\n",
    "  inds,edges,d2=graph_from_3D_mask(lbl)\n",
    "  #imshow(edges.astype(np.uint8)*255)\n",
    "  edges_nc,nodes_nc=detectAndRemoveClusters(edges)\n",
    "  inds_nc=inds[nodes_nc]\n",
    "  #imshow(edges_nc.astype(np.uint8)*255)\n",
    "  lbl_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_nc[inds_nc[k][0],inds_nc[k][1],inds_nc[k][2]]=1\n",
    "  show2Cubes(lbl_nc,lbl)\n",
    "  cycles_nc=minCycleBasis(edges_nc)\n",
    "  if len(cycles_nc)>0:\n",
    "    print(\"number cycles in the processed graph \",len(cycles_nc))\n",
    "    edges_rc,nodes_rc,res=removeCycles(edges_nc,cycles_nc)\n",
    "    inds_nc=inds_nc[nodes_rc]\n",
    "    edges_nc=edges_rc\n",
    "    if not res:\n",
    "        print(\"failed to remove a cycle\")\n",
    "        break\n",
    "  if not verifyEdges(edges_nc,inds_nc):\n",
    "    print(\"connection between non-neighboring voxels\")\n",
    "    break\n",
    "  num_cc_nc, component_labels_nc=g.connected_components(edges_nc)\n",
    "  lbl_color_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_color_nc[inds_nc[k][0],inds_nc[k][1],inds_nc[k][2]]=component_labels_nc[k]+1\n",
    "  lbl_color_nc=lbl_color_nc/float(num_cc_nc+1)\n",
    "  #showCube(lbl_color_nc)\n",
    "  #print( num_cc_nc )\n",
    "  num_cc, component_labels=g.connected_components(edges)\n",
    "  lbl_color=np.zeros_like(lbl)\n",
    "  for k in range(edges.shape[0]):\n",
    "    lbl_color[inds[k][0],inds[k][1],inds[k][2]]=component_labels[k]+1\n",
    "  lbl_color=lbl_color/float(num_cc+1)\n",
    "  show2Cubes(lbl_color,lbl_color_nc)\n",
    "  #print( num_cc )\n",
    "  if num_cc != num_cc_nc:\n",
    "    print(\"different number of connected components\")\n",
    "    break\n",
    "  assert(edges_nc.shape[0]==inds_nc.shape[0])\n",
    "  graphs.append([f,edges_nc,inds_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the graphs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graphs for test ground truths\n",
    "for gr in graphs:\n",
    "    ff=open(os.path.join(testgraphdir,gr[0][0]),\"bw\")\n",
    "    gt={'edges':gr[1],'node_coordinates':gr[2]}\n",
    "    pickle.dump(gt,ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the graphs and remove dangling nodes\n",
    "\n",
    "files=[trainFiles, testFiles]\n",
    "lbldirs=[lbldir,testlbldir]\n",
    "gdirs=[traingraphdir,testgraphdir]\n",
    "for fls,lds,gd in zip(files,lbldirs,gdirs):\n",
    "    print(lds)\n",
    "    for f in fls:\n",
    "        print(f)\n",
    "        ff=open(os.path.join(gd,f[1]),\"rb\")\n",
    "        gt=pickle.load(ff)\n",
    "        ff.close()\n",
    "        nc=gt['node_coordinates']\n",
    "        edges_graph=gt['edges']\n",
    "        dangling=checkDangling(edges_graph)\n",
    "        print(\"before removal, there were {} dangling nodes\".format(len(dangling)))\n",
    "        edges_graph,nc=removeDangling(edges_graph,nc)\n",
    "        dangling=checkDangling(edges_graph)\n",
    "        print(\"after removal, there were {} dangling nodes\".format(len(dangling)))\n",
    "        ff=open(os.path.join(gd,f[1]),\"bw\")\n",
    "        gt={'edges':edges_graph,'node_coordinates':nc}\n",
    "        pickle.dump(gt,ff)\n",
    "        ff.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# verify the saved data: both test and train graphs\n",
    "def colorComponents(lbl,edges,coords):\n",
    "    lbl_=np.zeros_like(lbl)\n",
    "    num_cc, component_labels=g.connected_components(edges)\n",
    "    for k in range(coords.shape[0]):\n",
    "        lbl_[coords[k][0],coords[k][1],coords[k][2]]=component_labels[k]+1\n",
    "    lbl_=lbl_/float(num_cc+1)\n",
    "    return lbl_,num_cc\n",
    "\n",
    "files=[trainFiles, testFiles]\n",
    "lbldirs=[lbldir,testlbldir]\n",
    "gdirs=[traingraphdir,testgraphdir]\n",
    "for fls,lds,gd in zip(files,lbldirs,gdirs):\n",
    "    print(lds)\n",
    "    for f in fls:\n",
    "        print(f)\n",
    "        lbl=np.load(os.path.join(lds,f[1])).astype(np.float32)\n",
    "        lbl[lbl<2]=0\n",
    "        lbl=lbl/2\n",
    "        inds,edges,d2=graph_from_3D_mask(lbl)\n",
    "        ff=open(os.path.join(gd,f[1]),\"rb\")\n",
    "        gt=pickle.load(ff)\n",
    "        ff.close()\n",
    "        nc=gt['node_coordinates']\n",
    "        edges_graph=gt['edges']\n",
    "        lbl_graph,n_graph=colorComponents(lbl,edges_graph,nc)\n",
    "        lbl_color,n_orig=colorComponents(lbl,edges,inds)\n",
    "        show3Cubes(lbl_color>0,(lbl_graph>0)!=(lbl_color>0),lbl_graph>0)\n",
    "        assert(n_graph==n_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
