{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import IPython.display \n",
    "import importlib\n",
    "import skimage.io as imgio\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from graph_routines import graph_from_3D_mask, graph_from_2D_mask, detectAndRemoveClusters, cycleBasis, reduceCycleBasis, minCycleBasis, verifyEdges\n",
    "import scipy.sparse.csgraph as g\n",
    "from skimage.morphology import skeletonize\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def imshow(img):\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "    \n",
    "def showImg(img1):\n",
    "    imshow(img1)\n",
    "def showImgs(imgs):\n",
    "    #return\n",
    "    imshow(np.concatenate(imgs,axis=1)*255)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_routines import detectAndRemoveClusters, cycleBasis, reduceCycleBasis, minCycleBasis, verifyEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir    = \"/cvlabdata2/cvlab/datasets_leo/isbi12_em/ours/train/images/\"\n",
    "lbldir    = \"/cvlabdata2/cvlab/datasets_leo/isbi12_em/ours/train/labels_thin/\"\n",
    "testimgdir= \"/cvlabdata2/cvlab/datasets_leo/isbi12_em/ours/test/images/\"\n",
    "testlbldir= \"/cvlabdata2/cvlab/datasets_leo/isbi12_em/ours/test/labels_thin/\"\n",
    "exec(open(\"testFiles_isbi12.txt\").read())\n",
    "exec(open(\"trainFiles_isbi12.txt\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"./graphs_isbi12/\"\n",
    "graphdir=os.path.join(datadir,\"lbl_graph\")\n",
    "#os.mkdir(graphdir)\n",
    "traingraphdir=os.path.join(graphdir,\"train\")\n",
    "#os.mkdir(traingraphdir)\n",
    "testgraphdir=os.path.join(graphdir,\"test\")\n",
    "#os.mkdir(testgraphdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeCycle(edges,cycle):\n",
    "    nodes_cycle=np.nonzero(cycle.reshape(edges.shape))[0]\n",
    "    for k in nodes_cycle:\n",
    "        if edges[k].sum()<3: # not connected to the outside of the cycle\n",
    "            return k,True\n",
    "    return 0,False\n",
    "\n",
    "def removeCycles(edges,cycles):\n",
    "    nodes= np.array(range(edges.shape[0]))\n",
    "    nodes_to_be_removed=[]\n",
    "    succ = True\n",
    "    for c in cycles:\n",
    "        if c.sum()<5 :\n",
    "            print(\"attempting to remove cycle length\",c.sum())\n",
    "            n,res=removeCycle(edges,c)\n",
    "            if res:\n",
    "                print(\"succeeded\")\n",
    "            else:\n",
    "                print(\"failed\")\n",
    "            succ=succ and res\n",
    "            if res:\n",
    "                nodes_to_be_removed.append(n)\n",
    "        else:\n",
    "            print(\"found cycle length {} but not removing it (too large)\",c.sum())\n",
    "    edges=np.delete(edges,nodes_to_be_removed,axis=0)\n",
    "    edges=np.delete(edges,nodes_to_be_removed,axis=1)\n",
    "    nodes=np.delete(nodes,nodes_to_be_removed,axis=0)\n",
    "    return edges,nodes,succ\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for single dangling nodes\n",
    "def checkDangling(edges):\n",
    "    dangling=[]\n",
    "    singlyConnected=np.nonzero(edges.sum(1)==1)[0]\n",
    "    for k in singlyConnected:\n",
    "        nb=np.argmax(edges[k]).item()\n",
    "        if edges[nb].sum()>2:\n",
    "            #print(\"dangling node\")\n",
    "            dangling.append(k)\n",
    "    return np.array(dangling)\n",
    "\n",
    "def removeDangling(edges,nodes):\n",
    "    k=0\n",
    "    while k<edges.shape[0]:\n",
    "        if edges[k].sum()==1:\n",
    "            # k is singly connected\n",
    "            nb=np.argmax(edges[k]).item()\n",
    "            if edges[nb].sum()>2:\n",
    "                # the only neighbor of k is multiply connected\n",
    "                # so k is a dangling node\n",
    "                edges=np.delete(edges,(k),0)\n",
    "                edges=np.delete(edges,(k),1)\n",
    "                nodes=np.delete(nodes,(k),0)\n",
    "                continue\n",
    "        k=k+1\n",
    "    return edges,nodes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slice_00.tiff', 'slice_00.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 213 clusters\n",
      "skeletonization time: 0.0021469593048095703\n",
      "graph extraction time 4.978541135787964\n",
      "cluster removal time 95.54733061790466\n",
      "rendering time 0.009526729583740234\n",
      "read {}/{} imageS 1 15\n",
      "['slice_01.tiff', 'slice_01.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 201 clusters\n",
      "skeletonization time: 0.002009868621826172\n",
      "graph extraction time 4.481921672821045\n",
      "cluster removal time 89.85636162757874\n",
      "rendering time 0.009084463119506836\n",
      "read {}/{} imageS 2 15\n",
      "['slice_02.tiff', 'slice_02.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 210 clusters\n",
      "skeletonization time: 0.0018167495727539062\n",
      "graph extraction time 5.018235445022583\n",
      "cluster removal time 94.1344940662384\n",
      "rendering time 0.009959220886230469\n",
      "read {}/{} imageS 3 15\n",
      "['slice_03.tiff', 'slice_03.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 189 clusters\n",
      "skeletonization time: 0.0017287731170654297\n",
      "graph extraction time 5.046301364898682\n",
      "cluster removal time 78.96561193466187\n",
      "rendering time 0.009606599807739258\n",
      "read {}/{} imageS 4 15\n",
      "['slice_04.tiff', 'slice_04.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 218 clusters\n",
      "skeletonization time: 0.0019049644470214844\n",
      "graph extraction time 4.936825275421143\n",
      "cluster removal time 102.04944133758545\n",
      "rendering time 0.00901031494140625\n",
      "read {}/{} imageS 5 15\n",
      "['slice_05.tiff', 'slice_05.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 190 clusters\n",
      "skeletonization time: 0.0017664432525634766\n",
      "graph extraction time 4.623314380645752\n",
      "cluster removal time 82.0601487159729\n",
      "rendering time 0.008941888809204102\n",
      "read {}/{} imageS 6 15\n",
      "['slice_06.tiff', 'slice_06.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 203 clusters\n",
      "skeletonization time: 0.002504110336303711\n",
      "graph extraction time 4.740844249725342\n",
      "cluster removal time 91.67544412612915\n",
      "rendering time 0.008907318115234375\n",
      "read {}/{} imageS 7 15\n",
      "['slice_07.tiff', 'slice_07.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 199 clusters\n",
      "skeletonization time: 0.0024924278259277344\n",
      "graph extraction time 4.392089366912842\n",
      "cluster removal time 79.46983528137207\n",
      "rendering time 0.009353160858154297\n",
      "read {}/{} imageS 8 15\n",
      "['slice_08.tiff', 'slice_08.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 207 clusters\n",
      "skeletonization time: 0.0029938220977783203\n",
      "graph extraction time 4.68823504447937\n",
      "cluster removal time 80.1379542350769\n",
      "rendering time 0.015472412109375\n",
      "read {}/{} imageS 9 15\n",
      "['slice_09.tiff', 'slice_09.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 221 clusters\n",
      "skeletonization time: 0.0015020370483398438\n",
      "graph extraction time 4.966876268386841\n",
      "cluster removal time 91.16286015510559\n",
      "rendering time 0.009521722793579102\n",
      "read {}/{} imageS 10 15\n",
      "['slice_10.tiff', 'slice_10.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 196 clusters\n",
      "skeletonization time: 0.0028820037841796875\n",
      "graph extraction time 4.086030006408691\n",
      "cluster removal time 76.41560554504395\n",
      "rendering time 0.01518702507019043\n",
      "read {}/{} imageS 11 15\n",
      "['slice_11.tiff', 'slice_11.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 166 clusters\n",
      "skeletonization time: 0.002269268035888672\n",
      "graph extraction time 3.5380144119262695\n",
      "cluster removal time 61.22688841819763\n",
      "rendering time 0.007699012756347656\n",
      "read {}/{} imageS 12 15\n",
      "['slice_12.tiff', 'slice_12.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 163 clusters\n",
      "skeletonization time: 0.0015554428100585938\n",
      "graph extraction time 3.4277799129486084\n",
      "cluster removal time 55.78888964653015\n",
      "rendering time 0.007664203643798828\n",
      "read {}/{} imageS 13 15\n",
      "['slice_13.tiff', 'slice_13.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 165 clusters\n",
      "skeletonization time: 0.0014407634735107422\n",
      "graph extraction time 3.2363369464874268\n",
      "cluster removal time 54.46251630783081\n",
      "rendering time 0.007893562316894531\n",
      "read {}/{} imageS 14 15\n",
      "['slice_14.tiff', 'slice_14.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 182 clusters\n",
      "skeletonization time: 0.0023047924041748047\n",
      "graph extraction time 3.482255458831787\n",
      "cluster removal time 59.63286805152893\n",
      "rendering time 0.007458925247192383\n",
      "read {}/{} imageS 15 15\n"
     ]
    }
   ],
   "source": [
    "# prepare graphs for training ground truths\n",
    "graphs=[]\n",
    "numfile=0\n",
    "for f in trainFiles:\n",
    "  numfile+=1\n",
    "  print(f)\n",
    "  img=imgio.imread(os.path.join(imgdir,f[0])).astype(np.float32)\n",
    "  lbl=imgio.imread(os.path.join(lbldir,f[1])).astype(np.float32)\n",
    "  print(img.shape)\n",
    "  #img=np.copy(img[:,0:100,0:100,0:100])\n",
    "  #lbl=np.copy(lbl[0:100,0:100,0:100])\n",
    "  lbl=lbl/255\n",
    "  print(np.unique(lbl))\n",
    "  t_skeleton=time.time()\n",
    "  lbl_skeletonized=skeletonize(lbl)\n",
    "  #showCube(lbl)\n",
    "  t_graph=time.time()\n",
    "  inds,edges,d2=graph_from_2D_mask(lbl)\n",
    "  print(\"got a graph\")\n",
    "  #imshow(edges.astype(np.uint8)*255)\n",
    "  t_clusters=time.time()\n",
    "  edges_nc,nodes_nc=detectAndRemoveClusters(edges)\n",
    "  inds_nc=inds[nodes_nc]\n",
    "  #imshow(edges_nc.astype(np.uint8)*255)\n",
    "  \n",
    "  t_rendering=time.time()\n",
    "  lbl_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_nc[inds_nc[k][0],inds_nc[k][1]]=1\n",
    "  #showImgs([lbl_nc,lbl])\n",
    "  \n",
    "  t_cycleBasis=time.time()\n",
    "  #cycles_nc=minCycleBasis(edges_nc)\n",
    "  #t_removeCycles=time.time()\n",
    "  #cycles_nc=minCycleBasis(edges_nc)\n",
    "  #if len(cycles_nc)>0:\n",
    "  #  print(\"number cycles in the processed graph \",len(cycles_nc))\n",
    "  #  edges_rc,nodes_rc,res=removeCycles(edges_nc,cycles_nc)\n",
    "  #  inds_nc=inds_nc[nodes_rc]\n",
    "  #  edges_nc=edges_rc\n",
    "  #  if not res:\n",
    "  #      print(\"failed to remove a cycle\")\n",
    "  #      break\n",
    "  if not verifyEdges(edges_nc,inds_nc):\n",
    "    print(\"connection between non-neighboring voxels\")\n",
    "    break\n",
    "  #num_cc_nc, component_labels_nc=g.connected_components(edges_nc)\n",
    "  #lbl_color_nc=np.zeros_like(lbl)\n",
    "  #for k in range(inds_nc.shape[0]):\n",
    "  #  lbl_color_nc[inds_nc[k][0],inds_nc[k][1]]=component_labels_nc[k]+1\n",
    "  #lbl_color_nc=lbl_color_nc/float(num_cc_nc+1)\n",
    "  #showCube(lbl_color_nc)\n",
    "  #print( num_cc_nc )\n",
    "  #num_cc, component_labels=g.connected_components(edges)\n",
    "  #lbl_color=np.zeros_like(lbl)\n",
    "  #for k in range(edges.shape[0]):\n",
    "  #  lbl_color[inds[k][0],inds[k][1]]=component_labels[k]+1\n",
    "  #lbl_color=lbl_color/float(num_cc+1)\n",
    "  #showImgs([lbl_color,lbl_color_nc])\n",
    "  #print( num_cc )\n",
    "  #if num_cc != num_cc_nc:\n",
    "  #  print(\"different number of connected components\")\n",
    "  #  break\n",
    "  #assert(edges_nc.shape[0]==inds_nc.shape[0])\n",
    "  graphs.append([f,edges_nc,inds_nc])\n",
    "  print(\"skeletonization time:\",t_graph-t_skeleton)\n",
    "  print(\"graph extraction time\",t_clusters-t_graph)\n",
    "  print(\"cluster removal time\",t_rendering-t_clusters)\n",
    "  print(\"rendering time\",t_cycleBasis-t_rendering)\n",
    "  #print(\"cycle basis time\",t_removeCycles-t_cycleBasis)\n",
    "  print(\"read {}/{} imageS\",numfile,len(testFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can check the graphs some more...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training ground truth graphs\n",
    "for gr in graphs:\n",
    "    ff=open(os.path.join(traingraphdir,gr[0][0]),\"bw\")\n",
    "    gt={'edges':gr[1],'node_coordinates':gr[2]}\n",
    "    pickle.dump(gt,ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slice_15.tiff', 'slice_15.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 167 clusters\n",
      "skeletonization time: 0.0017502307891845703\n",
      "graph extraction time 3.2756597995758057\n",
      "cluster removal time 58.145495653152466\n",
      "rendering time 0.007121086120605469\n",
      "read {}/{} imageS 1 15\n",
      "['slice_16.tiff', 'slice_16.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 163 clusters\n",
      "skeletonization time: 0.0015940666198730469\n",
      "graph extraction time 3.5918118953704834\n",
      "cluster removal time 55.645310163497925\n",
      "rendering time 0.0068836212158203125\n",
      "read {}/{} imageS 2 15\n",
      "['slice_17.tiff', 'slice_17.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 131 clusters\n",
      "skeletonization time: 0.0017802715301513672\n",
      "graph extraction time 3.2683160305023193\n",
      "cluster removal time 40.54846549034119\n",
      "rendering time 0.0073206424713134766\n",
      "read {}/{} imageS 3 15\n",
      "['slice_18.tiff', 'slice_18.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 140 clusters\n",
      "skeletonization time: 0.002180814743041992\n",
      "graph extraction time 2.684777021408081\n",
      "cluster removal time 40.94930076599121\n",
      "rendering time 0.006353855133056641\n",
      "read {}/{} imageS 4 15\n",
      "['slice_19.tiff', 'slice_19.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 143 clusters\n",
      "skeletonization time: 0.0013093948364257812\n",
      "graph extraction time 3.1382105350494385\n",
      "cluster removal time 48.118218660354614\n",
      "rendering time 0.006860494613647461\n",
      "read {}/{} imageS 5 15\n",
      "['slice_20.tiff', 'slice_20.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 140 clusters\n",
      "skeletonization time: 0.0017199516296386719\n",
      "graph extraction time 3.1305694580078125\n",
      "cluster removal time 44.04493474960327\n",
      "rendering time 0.006809234619140625\n",
      "read {}/{} imageS 6 15\n",
      "['slice_21.tiff', 'slice_21.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 150 clusters\n",
      "skeletonization time: 0.0015604496002197266\n",
      "graph extraction time 2.9245803356170654\n",
      "cluster removal time 48.45881414413452\n",
      "rendering time 0.007162332534790039\n",
      "read {}/{} imageS 7 15\n",
      "['slice_22.tiff', 'slice_22.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 144 clusters\n",
      "skeletonization time: 0.001466989517211914\n",
      "graph extraction time 2.883967161178589\n",
      "cluster removal time 46.49296760559082\n",
      "rendering time 0.007086992263793945\n",
      "read {}/{} imageS 8 15\n",
      "['slice_23.tiff', 'slice_23.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 167 clusters\n",
      "skeletonization time: 0.0015954971313476562\n",
      "graph extraction time 3.2262699604034424\n",
      "cluster removal time 54.73920702934265\n",
      "rendering time 0.006866455078125\n",
      "read {}/{} imageS 9 15\n",
      "['slice_24.tiff', 'slice_24.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 159 clusters\n",
      "skeletonization time: 0.002058267593383789\n",
      "graph extraction time 3.1345903873443604\n",
      "cluster removal time 55.67201256752014\n",
      "rendering time 0.006997823715209961\n",
      "read {}/{} imageS 10 15\n",
      "['slice_25.tiff', 'slice_25.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 157 clusters\n",
      "skeletonization time: 0.0014710426330566406\n",
      "graph extraction time 2.9806296825408936\n",
      "cluster removal time 51.71942973136902\n",
      "rendering time 0.006612539291381836\n",
      "read {}/{} imageS 11 15\n",
      "['slice_26.tiff', 'slice_26.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 173 clusters\n",
      "skeletonization time: 0.0013928413391113281\n",
      "graph extraction time 3.399263381958008\n",
      "cluster removal time 61.48715138435364\n",
      "rendering time 0.007684469223022461\n",
      "read {}/{} imageS 12 15\n",
      "['slice_27.tiff', 'slice_27.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 164 clusters\n",
      "skeletonization time: 0.0022017955780029297\n",
      "graph extraction time 4.027563095092773\n",
      "cluster removal time 67.01183080673218\n",
      "rendering time 0.007611751556396484\n",
      "read {}/{} imageS 13 15\n",
      "['slice_28.tiff', 'slice_28.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 171 clusters\n",
      "skeletonization time: 0.0014700889587402344\n",
      "graph extraction time 3.958256721496582\n",
      "cluster removal time 69.8828239440918\n",
      "rendering time 0.007750511169433594\n",
      "read {}/{} imageS 14 15\n",
      "['slice_29.tiff', 'slice_29.tiff']\n",
      "(512, 512)\n",
      "[0. 1.]\n",
      "got a graph\n",
      "there were 172 clusters\n",
      "skeletonization time: 0.0017316341400146484\n",
      "graph extraction time 3.5430655479431152\n",
      "cluster removal time 67.35884118080139\n",
      "rendering time 0.007788181304931641\n",
      "read {}/{} imageS 15 15\n"
     ]
    }
   ],
   "source": [
    "# prepare graphs for test ground truths\n",
    "graphs=[]\n",
    "numfile=0\n",
    "for f in testFiles:\n",
    "\n",
    "  numfile+=1\n",
    "  print(f)\n",
    "  img=imgio.imread(os.path.join(testimgdir,f[0])).astype(np.float32)\n",
    "  lbl=imgio.imread(os.path.join(testlbldir,f[1])).astype(np.float32)\n",
    "  print(img.shape)\n",
    "  #img=np.copy(img[:,0:100,0:100,0:100])\n",
    "  #lbl=np.copy(lbl[0:100,0:100,0:100])\n",
    "  lbl=lbl/255\n",
    "  print(np.unique(lbl))\n",
    "  t_skeleton=time.time()\n",
    "  lbl_skeletonized=skeletonize(lbl)\n",
    "  #showCube(lbl)\n",
    "  t_graph=time.time()\n",
    "  inds,edges,d2=graph_from_2D_mask(lbl)\n",
    "  print(\"got a graph\")\n",
    "  #imshow(edges.astype(np.uint8)*255)\n",
    "  t_clusters=time.time()\n",
    "  edges_nc,nodes_nc=detectAndRemoveClusters(edges)\n",
    "  inds_nc=inds[nodes_nc]\n",
    "  #imshow(edges_nc.astype(np.uint8)*255)\n",
    "  \n",
    "  t_rendering=time.time()\n",
    "  lbl_nc=np.zeros_like(lbl)\n",
    "  for k in range(inds_nc.shape[0]):\n",
    "    lbl_nc[inds_nc[k][0],inds_nc[k][1]]=1\n",
    "  #showImgs([lbl_nc,lbl])\n",
    "  \n",
    "  t_cycleBasis=time.time()\n",
    "  #cycles_nc=minCycleBasis(edges_nc)\n",
    "  #t_removeCycles=time.time()\n",
    "  #cycles_nc=minCycleBasis(edges_nc)\n",
    "  #if len(cycles_nc)>0:\n",
    "  #  print(\"number cycles in the processed graph \",len(cycles_nc))\n",
    "  #  edges_rc,nodes_rc,res=removeCycles(edges_nc,cycles_nc)\n",
    "  #  inds_nc=inds_nc[nodes_rc]\n",
    "  #  edges_nc=edges_rc\n",
    "  #  if not res:\n",
    "  #      print(\"failed to remove a cycle\")\n",
    "  #      break\n",
    "  if not verifyEdges(edges_nc,inds_nc):\n",
    "    print(\"connection between non-neighboring voxels\")\n",
    "    break\n",
    "  #num_cc_nc, component_labels_nc=g.connected_components(edges_nc)\n",
    "  #lbl_color_nc=np.zeros_like(lbl)\n",
    "  #for k in range(inds_nc.shape[0]):\n",
    "  #  lbl_color_nc[inds_nc[k][0],inds_nc[k][1]]=component_labels_nc[k]+1\n",
    "  #lbl_color_nc=lbl_color_nc/float(num_cc_nc+1)\n",
    "  #showCube(lbl_color_nc)\n",
    "  #print( num_cc_nc )\n",
    "  #num_cc, component_labels=g.connected_components(edges)\n",
    "  #lbl_color=np.zeros_like(lbl)\n",
    "  #for k in range(edges.shape[0]):\n",
    "  #  lbl_color[inds[k][0],inds[k][1]]=component_labels[k]+1\n",
    "  #lbl_color=lbl_color/float(num_cc+1)\n",
    "  #showImgs([lbl_color,lbl_color_nc])\n",
    "  #print( num_cc )\n",
    "  #if num_cc != num_cc_nc:\n",
    "  #  print(\"different number of connected components\")\n",
    "  #  break\n",
    "  #assert(edges_nc.shape[0]==inds_nc.shape[0])\n",
    "  graphs.append([f,edges_nc,inds_nc])\n",
    "  print(\"skeletonization time:\",t_graph-t_skeleton)\n",
    "  print(\"graph extraction time\",t_clusters-t_graph)\n",
    "  print(\"cluster removal time\",t_rendering-t_clusters)\n",
    "  print(\"rendering time\",t_cycleBasis-t_rendering)\n",
    "  #print(\"cycle basis time\",t_removeCycles-t_cycleBasis)\n",
    "  print(\"read {}/{} imageS\",numfile,len(trainFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the graphs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graphs for test ground truths\n",
    "for gr in graphs:\n",
    "    ff=open(os.path.join(testgraphdir,gr[0][0]),\"bw\")\n",
    "    gt={'edges':gr[1],'node_coordinates':gr[2]}\n",
    "    pickle.dump(gt,ff)\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the graphs and remove dangling nodes\n",
    "\n",
    "files=[trainFiles, testFiles]\n",
    "lbldirs=[lbldir,testlbldir]\n",
    "gdirs=[traingraphdir,testgraphdir]\n",
    "for fls,lds,gd in zip(files,lbldirs,gdirs):\n",
    "    print(lds)\n",
    "    for f in fls:\n",
    "        print(f)\n",
    "        ff=open(os.path.join(gd,f[1]),\"rb\")\n",
    "        gt=pickle.load(ff)\n",
    "        ff.close()\n",
    "        nc=gt['node_coordinates']\n",
    "        edges_graph=gt['edges']\n",
    "        dangling=checkDangling(edges_graph)\n",
    "        print(\"before removal, there were {} dangling nodes\".format(len(dangling)))\n",
    "        edges_graph,nc=removeDangling(edges_graph,nc)\n",
    "        dangling=checkDangling(edges_graph)\n",
    "        print(\"after removal, there were {} dangling nodes\".format(len(dangling)))\n",
    "        ff=open(os.path.join(gd,f[1]),\"bw\")\n",
    "        gt={'edges':edges_graph,'node_coordinates':nc}\n",
    "        pickle.dump(gt,ff)\n",
    "        ff.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# verify the saved data: both test and train graphs\n",
    "def colorComponents(lbl,edges,coords):\n",
    "    lbl_=np.zeros_like(lbl)\n",
    "    num_cc, component_labels=g.connected_components(edges)\n",
    "    for k in range(coords.shape[0]):\n",
    "        lbl_[coords[k][0],coords[k][1],coords[k][2]]=component_labels[k]+1\n",
    "    lbl_=lbl_/float(num_cc+1)\n",
    "    return lbl_,num_cc\n",
    "\n",
    "def colorComponents_2D(lbl,edges,coords):\n",
    "    lbl_=np.zeros_like(lbl)\n",
    "    num_cc, component_labels=g.connected_components(edges)\n",
    "    for k in range(coords.shape[0]):\n",
    "        lbl_[coords[k][0],coords[k][1]]=component_labels[k]+1\n",
    "    lbl_=lbl_/float(num_cc+1)\n",
    "    return lbl_,num_cc\n",
    "\n",
    "files=[trainFiles, testFiles]\n",
    "lbldirs=[lbldir,testlbldir]\n",
    "gdirs=[traingraphdir,testgraphdir]\n",
    "for fls,lds,gd in zip(files,lbldirs,gdirs):\n",
    "    print(lds)\n",
    "    for f in fls:\n",
    "        print(f)\n",
    "        #img=imgio.imread(os.path.join(testimgdir,f[0])).astype(np.float32)\n",
    "        lbl=imgio.imread(os.path.join(lds,f[1])).astype(np.float32)\n",
    "        #lbl=np.load(os.path.join(lds,f[1])).astype(np.float32)\n",
    "        #lbl[lbl<2]=0\n",
    "        lbl=lbl/255\n",
    "        inds,edges,d2=graph_from_2D_mask(lbl)\n",
    "        ff=open(os.path.join(gd,f[0]),\"rb\")\n",
    "        gt=pickle.load(ff)\n",
    "        ff.close()\n",
    "        nc=gt['node_coordinates']\n",
    "        edges_graph=gt['edges']\n",
    "        lbl_graph,n_graph=colorComponents_2D(lbl,edges_graph,nc)\n",
    "        lbl_color,n_orig=colorComponents_2D(lbl,edges,inds)\n",
    "        showImgs([lbl_color>0,(lbl_graph>0)!=(lbl_color>0),lbl_graph>0])\n",
    "        assert(n_graph==n_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
